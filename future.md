# the future of the world

* The Future We Deserve - 100 essays about the future: http://pediapress.com/books/show/ee265024890e40cbe1f8244087e753/
  * could be interesting, I like this topic
  * collections of essays are easier to read for lazy people like me

So far it seems to be there are 3 ways the future could go:

1. environmental disaster
  * fight for natural resources dominates our time
  * survival of human race itself is in question
  * "progress" is put on hold to attend to more immediate concerns
1. human-created power structures become too powerful (over human freedom)
  * like the world today, but *more*
  * the growth of current power structures - government/business
  * more people are reduced to mere cogs in a system
  * can envisage sum of all human activity as a higher level meta-organism (in the same way all the people in a company can change but the company continues - what *is* the company?)
1. computers take over the world
  * http://en.wikipedia.org/wiki/Technological_singularity
  * companies taking us in this direction:
    * [Boston Dynamics](http://www.bostondynamics.com/) - the mechanical moving part of the robots (bought by google 2013)
    * [Hanson Robotics](http://www.hansonrobotics.com/) - the bit that relates to humans, emotions, facial expressions, etc
    * [DeepMind](http://deepmind.com/) - the brainy bit (bought by google 2014)
    * many car companies making [self driving cars](http://en.wikipedia.org/wiki/Autonomous_car)
  * some pretty prominent people have entertained this idea in some form:
    * Alan Turing
    * Ray Kurzweil
    * Stephen Hawking
    * Elon Musk - "With artificial intelligence we are summoning the demon" ([washington post article](http://www.washingtonpost.com/blogs/innovations/wp/2014/10/24/elon-musk-with-artificial-intelligence-we-are-summoning-the-demon/))
    * Nick Bostrom
    * "5 Very Smart People Who Think Artificial Intelligence Could Bring the Apocalypse" - http://time.com/3614349/artificial-intelligence-singularity-stephen-hawking-elon-musk/
  * ... and many opponents
    * Paul Allen - http://www.technologyreview.com/view/425733/paul-allen-the-singularity-isnt-near/
    * http://www.patheos.com/blogs/hallq/2013/04/what-should-skeptics-believe-about-the-singularity/
      * don't know if that is opponent of it actually, didn't read it yet
    * http://www.spectator.co.uk/features/9252311/the-sheer-stupidity-of-artificial-intelligence/
      * says "A geek religion that aims to exalt machines instead diminishes humanity"

Well, and magic 4th option, the world I actually *want*, I call it the *garden of eden* :) - it looks a bit like [the shire](http://www.travelphotoadventures.com/wp-content/uploads/2012/12/Hobbiton-in-New-Zealand-by-Michael-Matti.jpg) from lord of the rings.

Or the *ultimate* end from death of the sun (which would be death of the earth, but maybe humanity has escaped in a magical spaceship by then).

Whichever one will happen first is the one we should fix, if we don't know which one will happen first, we should work on them all, until we have more information.

Maybe there are some other options though, this is probably not *all* the ways the future could go.

The important question is timescale too, is this 1 month (probably not), 1 year, 10 years, 100 years, 1000 years?

## Structural violence

Something about the difference between ideal and current. http://www.structuralviolence.org/structural-violence/. Haven't read it yet.
